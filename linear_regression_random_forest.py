# -*- coding: utf-8 -*-
"""Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yOZgaVW6P3je4kuhnpTxP6cMNERBTxwG
"""

!pip install praw

#import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

import plotly
plotly.offline.init_notebook_mode(connected=True)
from plotly.graph_objs import *
from plotly import tools
import plotly.graph_objects as go
import seaborn as sns


import praw
import networkx as nx
from datetime import datetime

df= pd.read_csv('/ethereum_subreddit_analysis.csv')

df.head(10)

df=df[0:950]

df

df.isna().sum()

#Import cryptocurrency dataset from kaggle for calculating the closing price of bitcoin and ethereum

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!kaggle datasets download -d tencars/392-crypto-currency-pairs-at-minute-resolution
!unzip 392-crypto-currency-pairs-at-minute-resolution.zip

df1 = pd.read_csv('ethusd.csv')

df1.head()

eth_close=df1
eth_close.loc[:, 'time'] = eth_close['time'].apply(lambda x: datetime.fromtimestamp(x/1000.0).strftime('%Y-%m-%d %H:%M:%S'))

eth_close=eth_close.drop(columns=["open","high","low","volume"])

eth_close

eth_close = eth_close.rename({'time': 'round_down_minute_datetime'}, axis=1)

eth_close.dtypes

eth_close['round_down_minute_datetime'] =  pd.to_datetime(eth_close['round_down_minute_datetime'], format='%Y-%m-%d %H:%M:%S')

eth_close[ 'rolling_average_30_mins' ] = eth_close.close.rolling(30).mean()

eth_close.tail()
eth_close=eth_close.drop(columns="close")

eth_close.head()

df["created"] = pd.to_datetime(df["created"])

df["round_down_minute_datetime"] = df["created"].dt.floor("min")

df_join = pd.merge(df,eth_close,on='round_down_minute_datetime')
df_join

df_join.isna().sum()

df2=pd.read_csv("/content/autor_influnce.csv")

df2

posts=df

#PRAW application ID and Secret
reddit = praw.Reddit(
    client_id="DDScYrlvPYFopqlOS3IReQ",
    client_secret="kOzq249feXHiuh3Y4moM8aC1sVaKHA",
    user_agent="Research",
)
reddit.read_only = True

graph = nx.DiGraph()
count = 0

for i, row in posts.iterrows():
    submission_id=posts.at[i,'id']
    post=reddit.submission(id=submission_id)
    print(count)
    count+=1
    if(post.author != None):
        author = post.author.name
        print(author)
        posts.at[i,'author'] = author

df2=df2.rename(columns={"author": "score", "score": "author"})

df_join1 = pd.merge(posts,df2,on='author')

dff=pd.merge(df_join1,eth_close,on='round_down_minute_datetime')

dff.isna().sum()

correl = dff.corr()

trace = go.Heatmap(z=correl.values,
                  x=correl.index.values,
                  y=correl.columns.values)
data=[trace]
plotly.offline.iplot(data, filename='basic-heatmap')

dff.columns

data= dff.drop(columns = ['Unnamed: 0_x', 'title','id', 'subreddit', 'url','created','round_down_minute_datetime', 'author', 'Unnamed: 0_y'])

data

data=data.drop(columns=['score_x','body'])

data

X_train, X_test, y_train, y_test = train_test_split(data.drop(columns = ['rolling_average_30_mins']), data['rolling_average_30_mins'], test_size=0.5, random_state=20)
# In the above split the stratify = y essentially makes sure the fractions of the classification is maintained

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = pd.DataFrame(sc.fit_transform(X_train), columns = X_train.columns, index = X_train.index)
X_test = pd.DataFrame(sc.transform(X_test), columns = X_test.columns, index = X_test.index)

X_train

X_test

y_train

y_test



#Linear Regression

model = LinearRegression(fit_intercept = True)
model.fit(X_train, y_train)

# The following gives the R-square score
model.score(X_train, y_train)

# This is the coefficient Beta_1, ..., Beta_7
model.coef_

# This is the coefficient Beta_0
model.intercept_

test_output1 = pd.DataFrame(model.predict(X_test), index = X_test.index, columns = ['pred_price'])
# When extending to multiple features remove .array.reshape(-1, 1)
test_output1.head()

model.score(X_test,y_test)

test_output1 = test_output1.merge(y_test, left_index = True, right_index = True)
test_output1.head()

test_output1[6:15]





mean_absolute_error = abs(test_output1['pred_price'] - test_output1['rolling_average_30_mins']).mean()
print('Mean absolute error is ')
print(mean_absolute_error)

predprice=test_output1['pred_price'].values.astype(int)



predprice

rollingav=test_output1['rolling_average_30_mins'].values.astype(int)









from sklearn.metrics import mean_squared_error

mean_squared_error(rollingav,predprice)

mean_squared_error(rollingav,predprice,squared=False)



abs(test_output1['pred_price'] - test_output1['rolling_average_30_mins']).mean()/test_output1['rolling_average_30_mins'].mean()



from sklearn.preprocessing import RobustScaler
rc = RobustScaler()
X1_train = pd.DataFrame(rc.fit_transform(X_train), columns = X_train.columns)
X1_test = pd.DataFrame(rc.transform(X_test), columns = X_test.columns)
X1_train
X1_test
y_train
y_test

# model = LinearRegression(fit_intercept = True)
# model = Lasso(alpha = 0.1, fit_intercept = True)
model1 = Lasso(alpha = 100, fit_intercept = True, max_iter=10000)
# model = Ridge(alpha = 20, fit_intercept = True)
model1.fit(X1_train, y_train)

# The following gives the R-square score
model1.score(X1_train, y_train)

# This is the coefficient Beta_1, ..., Beta_7
model1.coef_

# This is the coefficient Beta_0
model1.intercept_

test_output2 = pd.DataFrame(model1.predict(X_test), index = X_test.index, columns = ['pred_'])
# When extending to multiple features remove .array.reshape(-1, 1)
test_output2.head()

test_output2 = test_output2.merge(y_test, left_index = True, right_index = True)
test_output2.head()

mean_absolute_error = abs(test_output2['pred_'] - test_output2['rolling_average_30_mins']).mean()
print('Mean absolute error is ')
print(mean_absolute_error)

model1.score(X_test, y_test)



from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=100)
rf.fit(X_train, y_train)

rf.feature_importances_

test_output4 = pd.DataFrame(rf.predict(X_test), index = X_test.index, columns = ['pred'])
test_output4.head()

test_output4 = test_output4.merge(y_test, left_index = True, right_index = True)
test_output4.head()

test_output4[1:11]

mean_absolute_error = abs(test_output4['pred'] - test_output4['rolling_average_30_mins']).mean()
print('Mean absolute error is ')
print(mean_absolute_error)

rf.score(X_train,y_train)

rf.score(X_test,y_test)

rolling=test_output4['rolling_average_30_mins'].values.astype(int)

predprice1=test_output4['pred'].values.astype(int)

mean_squared_error(rolling,predprice1)

mean_squared_error(rolling,predprice1,squared=False)



